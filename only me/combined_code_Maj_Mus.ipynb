{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# immoweb house and apartment fore sale's page\n",
    "immoweb_sale_link = 'https://www.immoweb.be/en/search/house-and-apartment/for-sale?countries=BE&page=1&orderBy=relevance'\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# generating the links of 333 pages \n",
    "\n",
    "first_group_pages_link_sale = 'https://www.immoweb.be/en/search/house-and-apartment/for-sale?countries=BE&amp%3BorderBy=relevance&amp%3Bpage=2'\n",
    "p = 1\n",
    "last_p = 333\n",
    "group_pages_link_sale = []\n",
    "\n",
    "# adding 1st page in 1st cell of list\n",
    "group_pages_link_sale.append(first_group_pages_link_sale)\n",
    "\n",
    "for p in range(2,last_p+1):  \n",
    "    group_pages_link_sale.append(first_group_pages_link_sale +\"&page=\" + str(p))   # adding the link + new number of pages\n",
    "\n",
    "#group_pages_link_sale\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# extracting all linkes (+10000 links) for sale from immoweb// by group_pages_link_sale\n",
    "\n",
    "all_links = []              \n",
    "\n",
    "\n",
    "\n",
    "group_pages_link_sale_test = group_pages_link_sale[:33]\n",
    "\n",
    "for l in group_pages_link_sale_test:          # a loop to scrape that 333 group pages of immoweb\n",
    "\n",
    "    session = requests.Session()               \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "    }\n",
    "    response = session.get(l, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    for tag_a in soup.find_all('a', class_=\"card__title-link\", href=True):   # extracting all item links paer group page\n",
    "        all_links.append(tag_a['href'])\n",
    "\n",
    "#all_links \n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# input all links as a csv file\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('C:\\\\Users\\\\becod\\\\AI\\\\my-projects\\\\Majid_immoeliza_scraping\\\\links\\\\all_linkes.csv')\n",
    "\n",
    "# Show the first few rows of the data\n",
    "print(df.head())\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# List_url = [\n",
    "#     \"https://www.immoweb.be/en/classified/penthouse/for-sale/etterbeek/1040/20232667\",\n",
    "#     \"https://www.immoweb.be/en/classified/house/for-sale/kortrijk/8500/20234460\",\n",
    "#     \"https://www.immoweb.be/nl/zoekertje/huis/te-koop/amay/4540/20215296\",\n",
    "#     \"https://www.immoweb.be/en/classified/house/for-sale/wavre/1300/20231046\",\n",
    "#     \"https://www.immoweb.be/en/classified/apartment/for-sale/saint-gilles/1060/20234144\",\n",
    "# ]\n",
    "\n",
    "def request_url(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    req = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "    property_details = []\n",
    "\n",
    "    try:\n",
    "        html = soup.find(\"meta\", {\"property\": \"og:url\"}).get(\"content\")\n",
    "        html_list = html.split(\"/\")\n",
    "        Property_ID = html_list[-1]\n",
    "    except:\n",
    "        Property_ID = None\n",
    "    try:\n",
    "        postal_code = html_list[-2]\n",
    "    except:\n",
    "        postal_code = None\n",
    "    try:\n",
    "        locality = html_list[-3]\n",
    "    except:\n",
    "        locality = None\n",
    "    try:\n",
    "        home_meta_info = soup.find_all(\"div\", {\"class\": \"grid__item desktop--9\"})\n",
    "\n",
    "        price = (\n",
    "            home_meta_info[0]\n",
    "            .find(\"p\", {\"class\": \"classified__price\"})\n",
    "            .find_all(\"span\", {\"class\": \"sr-only\"})[0]\n",
    "         .text.strip()\n",
    "        )\n",
    "        print(price)\n",
    "\n",
    "        if price:\n",
    "            price = re.sub(r\"\\D\", \"\", price)  # remoning all non number characters\n",
    "            price = int(price) if price else None  # converting to a number if its not empty\n",
    "\n",
    "    except:\n",
    "        price = None\n",
    "    try:\n",
    "        Type_of_property = (\n",
    "            home_meta_info[0]\n",
    "            .find(\"h1\", {\"class\": \"classified__title\"})\n",
    "            .text.strip()[0:11]\n",
    "        )  # the second [0:11] just to return the property type\n",
    "    except:\n",
    "        Type_of_property = None\n",
    "    try:\n",
    "        home_prop_info = soup.find_all(\"div\", {\"class\": \"text-block__body\"})[\n",
    "            0\n",
    "        ].find_all(\"div\", {\"class\": \"overview__column\"})\n",
    "        bed_rooms = (\n",
    "            home_prop_info[0]\n",
    "            .find_all(\"div\", {\"class\": \"overview__item\"})[0]\n",
    "            .find_all(\"span\", {\"class\": \"overview__text\"})[0]\n",
    "            .text.strip()\n",
    "        )\n",
    "    except:\n",
    "        bed_rooms = None\n",
    "    try:\n",
    "        space = (\n",
    "            home_prop_info[1]\n",
    "            .find_all(\"div\", {\"class\": \"overview__item\"})[0]\n",
    "            .find_all(\"span\", {\"class\": \"overview__text\"})[0]\n",
    "            .text.strip()\n",
    "        )\n",
    "        space = re.findall(r\"\\d+\", space)[0]  # Extract only the digits\n",
    "    except:\n",
    "        space = None\n",
    "        \n",
    "    ######################## check this one again for different name ######################## try elif on the original one\n",
    "    try:\n",
    "        kitchen_keywords = (\n",
    "            \"Kitchen type\",\n",
    "            \"Type of kitchen\",\n",
    "        )  # as sometimes it has one of these names\n",
    "        kitchen_th = soup.find(\n",
    "            \"th\", string=lambda x: x and x.strip() in kitchen_keywords\n",
    "        )\n",
    "        if kitchen_th:\n",
    "            kitchen = kitchen_th.find_next_sibling(\"td\").contents[0].strip()\n",
    "            print(kitchen)\n",
    "\n",
    "            # Now, check for the kitchen types you're interested in\n",
    "            if kitchen in (\n",
    "                \"Installed\",\n",
    "                \"Installed\",\n",
    "                \"Hyper equipped\",\n",
    "                \"USA  Hyper equipped\",\n",
    "                \"Semi equipped\",\n",
    "                \"USA hyper equipped\",\n",
    "            ):\n",
    "                kitchen_type = 1\n",
    "            else:\n",
    "                kitchen_type = 0\n",
    "        else:\n",
    "            kitchen_type = (\n",
    "                0  # Default value if 'Kitchen type' or 'Type of kitchen' not found\n",
    "            )\n",
    "    except:\n",
    "        kitchen_type = None\n",
    "    # Building cindition\n",
    "    try:\n",
    "        building_condition_header = soup.find(\n",
    "            \"th\", string=lambda x: x and x.strip() == \"Building condition\"\n",
    "        ).find_parent(\"tr\")\n",
    "\n",
    "        building_condition = (\n",
    "            building_condition_header.find(\"td\", class_=\"classified-table__data\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "    except:\n",
    "        building_condition = None\n",
    "    # Number of facades   Number of facades\n",
    "    ############################# the same problem as kitchen, it might be named \"Number of facades\" #############\n",
    "    try:\n",
    "        facades = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"Number of frontages\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "\n",
    "        if facades:\n",
    "            Number_of_facades = facades\n",
    "        else:\n",
    "            Number_of_facades = 0\n",
    "    except:\n",
    "        Number_of_facades = None\n",
    "        \n",
    "    # Furnished\n",
    "    ############################# the same problem as kitchen, it might be named \"State of the building\" #############\n",
    "    try:\n",
    "        Furnished = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"Furnished\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "        if Furnished == \"Yes\":\n",
    "            Furnished = 1\n",
    "        else:\n",
    "            Furnished = 0\n",
    "    except:\n",
    "        Furnished = None\n",
    "    # open fire space\n",
    "    try:\n",
    "        Open_fire = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"How many fireplaces?\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "        if Open_fire:\n",
    "            Open_fire = 1\n",
    "        else:\n",
    "            Open_fire = 0\n",
    "    except:\n",
    "        Open_fire = None\n",
    "    # Swimming_pool\n",
    "    try:\n",
    "        Swimming_pool = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"Swimming pool\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "        if Swimming_pool == \"Yes\":\n",
    "            Swimming_pool = 1\n",
    "        else:\n",
    "            Swimming_pool = 0\n",
    "    except:\n",
    "        Swimming_pool = None\n",
    "    # Garden\n",
    "    ############################### Different name \"Garden area\" ###########################\n",
    "    try:\n",
    "        garden = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"Garden surface\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "        if garden:\n",
    "            garden = garden\n",
    "        else:\n",
    "            garden = None\n",
    "    except:\n",
    "        garden = None\n",
    "    # Terrace\n",
    "    ################################## It might have value only \"Yes\" or differnt name like \"Terrace surface area\" #########################\n",
    "    try:\n",
    "        Terrace = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"Terrace surface\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "        if Terrace:\n",
    "            Terrace = Terrace\n",
    "        else:\n",
    "            Terrace = None\n",
    "\n",
    "    except:\n",
    "        Terrace = None\n",
    "\n",
    "    property_details.append(\n",
    "        {\n",
    "            \"Property ID\": Property_ID,\n",
    "            \"Postal code\": postal_code,\n",
    "            \"Locality name\": locality,\n",
    "            \"Price\": price,\n",
    "            \"Type of property\": Type_of_property,\n",
    "            \"Number of rooms\": bed_rooms,\n",
    "            \"Living area\": space,\n",
    "            \"Equipped kitchen\": kitchen_type,\n",
    "            \"State of building\": building_condition,\n",
    "            \"Number of facades\": Number_of_facades, #facades,\n",
    "            \"Furnished\": Furnished,\n",
    "            \"Open fire\": Open_fire,\n",
    "            \"Swimming pool\": Swimming_pool,\n",
    "            \"Garden (m²)\": garden,\n",
    "            \"Terrace (m²)\": Terrace,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return property_details\n",
    "\n",
    "\n",
    "# Assuming List_url contains your URLs\n",
    "all_property_details = []\n",
    "for url in all_links: #List_url:\n",
    "    all_property_details.extend(request_url(url))\n",
    "\n",
    "# Convert the list of dictionaries to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_property_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\n",
    "    \"C:\\\\Users\\\\becod\\\\AI\\\\my-projects\\\\Majid_immoeliza_scraping\\\\all_linkes.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "print(\"extracted data saved in CSv file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combined code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325000€\n",
      "Installed\n",
      "249900€\n",
      "375000€\n",
      "Installed\n",
      "From 133000€ To 335000€\n",
      "From 149000€ To 382000€\n",
      "From 159325€ To 447375€\n",
      "From 159325€ To 447375€\n",
      "From 218586€ To 394026€\n",
      "From 232000€ To 297000€\n",
      "From 235000€ To 499000€\n",
      "From 240000€ To 528000€\n",
      "From 260000€ To 465000€\n",
      "From 260000€ To 265000€\n",
      "From 260250€ To 304000€\n",
      "From 273700€ To 382150€\n",
      "From 273700€ To 382500€\n",
      "From 274000€ To 339000€\n",
      "From 275000€ To 995000€\n",
      "From 276500€ To 332000€\n",
      "281000€\n",
      "From 286000€ To 462000€\n",
      "From 299500€ To 319000€\n",
      "From 301948€ To 556453€\n",
      "From 320000€ To 850000€\n",
      "From 325000€ To 366000€\n",
      "335000€\n",
      "336500€\n",
      "From 340000€ To 1435000€\n",
      "From 340000€ To 621000€\n",
      "From 344000€ To 459000€\n",
      "1699000€\n",
      "465000€\n",
      "435000€\n",
      "1150000€\n",
      "215000€\n",
      "325000€\n",
      "249000€\n",
      "249000€\n",
      "550000€\n",
      "Installed\n",
      "425000€\n",
      "326000€\n",
      "Semi equipped\n",
      "249000€\n",
      "Installed\n",
      "375000€\n",
      "Installed\n",
      "749000€\n",
      "Not installed\n",
      "150000€\n",
      "Installed\n",
      "239000€\n",
      "309000€\n",
      "295000€\n",
      "Installed\n",
      "550000€\n",
      "Installed\n",
      "354000€\n",
      "975000€\n",
      "Installed\n",
      "315000€\n",
      "285000€\n",
      "199000€\n",
      "185000€\n",
      "Semi equipped\n",
      "415000€\n",
      "Installed\n",
      "390000€\n",
      "595000€\n",
      "Hyper equipped\n",
      "274000€\n",
      "Hyper equipped\n",
      "135000€\n",
      "Semi equipped\n",
      "From 347400€ To 394600€\n",
      "From 349000€ To 363000€\n",
      "349000€\n",
      "From 350000€ To 379000€\n",
      "From 355000€ To 374000€\n",
      "From 360000€ To 430000€\n",
      "From 364000€ To 379000€\n",
      "365000€\n",
      "From 365000€ To 397000€\n",
      "From 367000€ To 444000€\n",
      "From 404500€ To 450000€\n",
      "From 407000€ To 443000€\n",
      "From 430000€ To 525000€\n",
      "From 455600€ To 542214€\n",
      "From 615000€ To 765000€\n",
      "From 774500€ To 808500€\n",
      "From 1200000€ To 1375000€\n",
      "225000€\n",
      "Installed\n",
      "225000€\n",
      "Installed\n",
      "229000€\n",
      "550000€\n",
      "Installed\n",
      "From 169500€ To 389000€\n",
      "From 169500€ To 389000€\n",
      "From 188000€ To 265000€\n",
      "From 188000€ To 460000€\n",
      "From 188000€ To 460000€\n",
      "From 230000€ To 480000€\n",
      "From 230000€ To 480000€\n",
      "From 249000€ To 349000€\n",
      "From 265000€ To 1495000€\n",
      "199000€\n",
      "Hyper equipped\n",
      "339000€\n",
      "Hyper equipped\n",
      "799000€\n",
      "Hyper equipped\n",
      "799900€\n",
      "Hyper equipped\n",
      "915000€\n",
      "Hyper equipped\n",
      "399000€\n",
      "915000€\n",
      "Hyper equipped\n",
      "700500€\n",
      "460500€\n",
      "325000€\n",
      "Hyper equipped\n",
      "450500€\n",
      "490500€\n",
      "209000€\n",
      "219000€\n",
      "125000€\n",
      "888888€\n",
      "Installed\n",
      "322003€\n",
      "Installed\n",
      "650000€\n",
      "Installed\n",
      "227249€\n",
      "Installed\n",
      "219000€\n",
      "Not installed\n",
      "227964€\n",
      "Installed\n",
      "519000€\n",
      "199000€\n",
      "From 190617€ To 322003€\n",
      "225902€\n",
      "220778€\n",
      "Installed\n",
      "215117€\n",
      "Installed\n",
      "270000€\n",
      "Semi equipped\n",
      "230667€\n",
      "359000€\n",
      "From 265000€ To 500000€\n",
      "From 265000€ To 570000€\n",
      "From 265000€ To 500000€\n",
      "From 269000€ To 469000€\n",
      "From 295000€ To 445000€\n",
      "From 295000€ To 445000€\n",
      "From 310000€ To 400000€\n",
      "From 310000€ To 400000€\n",
      "From 310000€ To 400000€\n",
      "From 315000€ To 390000€\n",
      "From 315000€ To 390000€\n",
      "From 315000€ To 319000€\n",
      "From 320000€ To 465000€\n",
      "From 325000€ To 410000€\n",
      "335000€\n",
      "From 337000€ To 383011€\n",
      "From 370000€ To 396000€\n",
      "From 420000€ To 495000€\n",
      "From 458000€ To 465000€\n",
      "From 467000€ To 547500€\n",
      "From 481000€ To 521000€\n",
      "From 481000€ To 521000€\n",
      "From 481000€ To 506000€\n",
      "From 485000€ To 580000€\n",
      "From 498000€ To 585000€\n",
      "From 534000€ To 585000€\n",
      "543000€\n",
      "From 679000€ To 725000€\n",
      "189000€\n",
      "389900€\n",
      "Hyper equipped\n",
      "700000€\n",
      "285000€\n",
      "Semi equipped\n",
      "199000€\n",
      "Not installed\n",
      "180000€\n",
      "Not installed\n",
      "450000€\n",
      "59000€\n",
      "199000€\n",
      "Semi equipped\n",
      "330000€\n",
      "290000€\n",
      "Installed\n",
      "195000€\n",
      "241359€\n",
      "Installed\n",
      "199000€\n",
      "Installed\n",
      "225000€\n",
      "Semi equipped\n",
      "110000€\n",
      "1270000€\n",
      "1065000€\n",
      "Installed\n",
      "199000€\n",
      "Installed\n",
      "199000€\n",
      "Semi equipped\n",
      "325000€\n",
      "Installed\n",
      "235000€\n",
      "235000€\n",
      "Installed\n",
      "215000€\n",
      "190617€\n",
      "Installed\n",
      "95000€\n",
      "195000€\n",
      "Not installed\n",
      "140000€\n",
      "Not installed\n",
      "189000€\n",
      "700000€\n",
      "Installed\n",
      "70000€\n",
      "199000€\n",
      "Not installed\n",
      "extracted data saved in CSv file\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# immoweb house and apartment fore sale's page\n",
    "immoweb_sale_link = 'https://www.immoweb.be/en/search/house-and-apartment/for-sale?countries=BE&page=1&orderBy=relevance'\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# generating the links of 333 pages \n",
    "\n",
    "first_group_pages_link_sale = 'https://www.immoweb.be/en/search/house-and-apartment/for-sale?countries=BE&amp%3BorderBy=relevance&amp%3Bpage=2'\n",
    "p = 1\n",
    "last_p = 333\n",
    "group_pages_link_sale = []\n",
    "\n",
    "# adding 1st page in 1st cell of list\n",
    "group_pages_link_sale.append(first_group_pages_link_sale)\n",
    "\n",
    "for p in range(2,last_p+1):  \n",
    "    group_pages_link_sale.append(first_group_pages_link_sale +\"&page=\" + str(p))   # adding the link + new number of pages\n",
    "\n",
    "#group_pages_link_sale\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# extracting all linkes (+10000 links) for sale from immoweb// by group_pages_link_sale\n",
    "\n",
    "all_links = []              \n",
    "\n",
    "\n",
    "\n",
    "group_pages_link_sale_test = group_pages_link_sale[:3]\n",
    "\n",
    "for l in group_pages_link_sale_test:          # a loop to scrape that 333 group pages of immoweb\n",
    "\n",
    "    session = requests.Session()               \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "    }\n",
    "    response = session.get(l, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    for tag_a in soup.find_all('a', class_=\"card__title-link\", href=True):   # extracting all item links paer group page\n",
    "        all_links.append(tag_a['href'])\n",
    "\n",
    "#all_links \n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# List_url = [\n",
    "#     \"https://www.immoweb.be/en/classified/penthouse/for-sale/etterbeek/1040/20232667\",\n",
    "#     \"https://www.immoweb.be/en/classified/house/for-sale/kortrijk/8500/20234460\",\n",
    "#     \"https://www.immoweb.be/nl/zoekertje/huis/te-koop/amay/4540/20215296\",\n",
    "#     \"https://www.immoweb.be/en/classified/house/for-sale/wavre/1300/20231046\",\n",
    "#     \"https://www.immoweb.be/en/classified/apartment/for-sale/saint-gilles/1060/20234144\",\n",
    "# ]\n",
    "\n",
    "def request_url(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    req = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "    property_details = []\n",
    "\n",
    "    try:\n",
    "        html = soup.find(\"meta\", {\"property\": \"og:url\"}).get(\"content\")\n",
    "        html_list = html.split(\"/\")\n",
    "        Property_ID = html_list[-1]\n",
    "    except:\n",
    "        Property_ID = None\n",
    "    try:\n",
    "        postal_code = html_list[-2]\n",
    "    except:\n",
    "        postal_code = None\n",
    "    try:\n",
    "        locality = html_list[-3]\n",
    "    except:\n",
    "        locality = None\n",
    "    try:\n",
    "        home_meta_info = soup.find_all(\"div\", {\"class\": \"grid__item desktop--9\"})\n",
    "\n",
    "        price = (\n",
    "            home_meta_info[0]\n",
    "            .find(\"p\", {\"class\": \"classified__price\"})\n",
    "            .find_all(\"span\", {\"class\": \"sr-only\"})[0]\n",
    "         .text.strip()\n",
    "        )\n",
    "        print(price)\n",
    "\n",
    "        if price:\n",
    "            price = re.sub(r\"\\D\", \"\", price)  # remoning all non number characters\n",
    "            price = int(price) if price else None  # converting to a number if its not empty\n",
    "\n",
    "    except:\n",
    "        price = None\n",
    "    try:\n",
    "        Type_of_property = (\n",
    "            home_meta_info[0]\n",
    "            .find(\"h1\", {\"class\": \"classified__title\"})\n",
    "            .text.strip()[0:11]\n",
    "        )  # the second [0:11] just to return the property type\n",
    "    except:\n",
    "        Type_of_property = None\n",
    "    try:\n",
    "        home_prop_info = soup.find_all(\"div\", {\"class\": \"text-block__body\"})[\n",
    "            0\n",
    "        ].find_all(\"div\", {\"class\": \"overview__column\"})\n",
    "        bed_rooms = (\n",
    "            home_prop_info[0]\n",
    "            .find_all(\"div\", {\"class\": \"overview__item\"})[0]\n",
    "            .find_all(\"span\", {\"class\": \"overview__text\"})[0]\n",
    "            .text.strip()\n",
    "        )\n",
    "    except:\n",
    "        bed_rooms = None\n",
    "    try:\n",
    "        space = (\n",
    "            home_prop_info[1]\n",
    "            .find_all(\"div\", {\"class\": \"overview__item\"})[0]\n",
    "            .find_all(\"span\", {\"class\": \"overview__text\"})[0]\n",
    "            .text.strip()\n",
    "        )\n",
    "        space = re.findall(r\"\\d+\", space)[0]  # Extract only the digits\n",
    "    except:\n",
    "        space = None\n",
    "        \n",
    "    ######################## check this one again for different name ######################## try elif on the original one\n",
    "    try:\n",
    "        kitchen_keywords = (\n",
    "            \"Kitchen type\",\n",
    "            \"Type of kitchen\",\n",
    "        )  # as sometimes it has one of these names\n",
    "        kitchen_th = soup.find(\n",
    "            \"th\", string=lambda x: x and x.strip() in kitchen_keywords\n",
    "        )\n",
    "        if kitchen_th:\n",
    "            kitchen = kitchen_th.find_next_sibling(\"td\").contents[0].strip()\n",
    "            print(kitchen)\n",
    "\n",
    "            # Now, check for the kitchen types you're interested in\n",
    "            if kitchen in (\n",
    "                \"Installed\",\n",
    "                \"Installed\",\n",
    "                \"Hyper equipped\",\n",
    "                \"USA  Hyper equipped\",\n",
    "                \"Semi equipped\",\n",
    "                \"USA hyper equipped\",\n",
    "            ):\n",
    "                kitchen_type = 1\n",
    "            else:\n",
    "                kitchen_type = 0\n",
    "        else:\n",
    "            kitchen_type = (\n",
    "                0  # Default value if 'Kitchen type' or 'Type of kitchen' not found\n",
    "            )\n",
    "    except:\n",
    "        kitchen_type = None\n",
    "    # Building cindition\n",
    "    try:\n",
    "        building_condition_header = soup.find(\n",
    "            \"th\", string=lambda x: x and x.strip() == \"Building condition\"\n",
    "        ).find_parent(\"tr\")\n",
    "\n",
    "        building_condition = (\n",
    "            building_condition_header.find(\"td\", class_=\"classified-table__data\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "    except:\n",
    "        building_condition = None\n",
    "    # Number of facades   Number of facades\n",
    "    ############################# the same problem as kitchen, it might be named \"Number of facades\" #############\n",
    "    try:\n",
    "        facades = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"Number of frontages\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "\n",
    "        if facades:\n",
    "            Number_of_facades = facades\n",
    "        else:\n",
    "            Number_of_facades = 0\n",
    "    except:\n",
    "        Number_of_facades = None\n",
    "        \n",
    "    # Furnished\n",
    "    ############################# the same problem as kitchen, it might be named \"State of the building\" #############\n",
    "    try:\n",
    "        Furnished = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"Furnished\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "        if Furnished == \"Yes\":\n",
    "            Furnished = 1\n",
    "        else:\n",
    "            Furnished = 0\n",
    "    except:\n",
    "        Furnished = None\n",
    "    # open fire space\n",
    "    try:\n",
    "        Open_fire = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"How many fireplaces?\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "        if Open_fire:\n",
    "            Open_fire = 1\n",
    "        else:\n",
    "            Open_fire = 0\n",
    "    except:\n",
    "        Open_fire = None\n",
    "    # Swimming_pool\n",
    "    try:\n",
    "        Swimming_pool = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"Swimming pool\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "        if Swimming_pool == \"Yes\":\n",
    "            Swimming_pool = 1\n",
    "        else:\n",
    "            Swimming_pool = 0\n",
    "    except:\n",
    "        Swimming_pool = None\n",
    "    # Garden\n",
    "    ############################### Different name \"Garden area\" ###########################\n",
    "    try:\n",
    "        garden = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"Garden surface\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "        if garden:\n",
    "            garden = garden\n",
    "        else:\n",
    "            garden = None\n",
    "    except:\n",
    "        garden = None\n",
    "    # Terrace\n",
    "    ################################## It might have value only \"Yes\" or differnt name like \"Terrace surface area\" #########################\n",
    "    try:\n",
    "        Terrace = (\n",
    "            soup.find(\"th\", string=lambda x: x and x.strip() == \"Terrace surface\")\n",
    "            .find_next_sibling(\"td\")\n",
    "            .contents[0]\n",
    "            .strip()\n",
    "        )\n",
    "        if Terrace:\n",
    "            Terrace = Terrace\n",
    "        else:\n",
    "            Terrace = None\n",
    "\n",
    "    except:\n",
    "        Terrace = None\n",
    "\n",
    "    property_details.append(\n",
    "        {\n",
    "            \"Property ID\": Property_ID,\n",
    "            \"Postal code\": postal_code,\n",
    "            \"Locality name\": locality,\n",
    "            \"Price\": price,\n",
    "            \"Type of property\": Type_of_property,\n",
    "            \"Number of rooms\": bed_rooms,\n",
    "            \"Living area\": space,\n",
    "            \"Equipped kitchen\": kitchen_type,\n",
    "            \"State of building\": building_condition,\n",
    "            \"Number of facades\": Number_of_facades, #facades,\n",
    "            \"Furnished\": Furnished,\n",
    "            \"Open fire\": Open_fire,\n",
    "            \"Swimming pool\": Swimming_pool,\n",
    "            \"Garden (m²)\": garden,\n",
    "            \"Terrace (m²)\": Terrace,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return property_details\n",
    "\n",
    "\n",
    "# Assuming List_url contains your URLs\n",
    "all_property_details = []\n",
    "for url in all_links: #List_url:\n",
    "    all_property_details.extend(request_url(url))\n",
    "\n",
    "# Convert the list of dictionaries to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_property_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\n",
    "    #\"C:\\\\Users\\\\mgabi\\\\Desktop\\\\becode\\\\becode_projects\\\\immoweb_scraping\\\\property_details.csv\",\n",
    "    \"C:\\\\Users\\\\becod\\\\AI\\\\my-projects\\\\Majid_immoeliza_scraping\\\\links\\\\all_linkes.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "print(\"extracted data saved in CSv file\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
